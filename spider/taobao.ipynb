import requests
import ssl

ssl._create_default_https_context = ssl._create_unverified_context
import re
import time
import pandas as pd
import string
import pandas as pd
import numpy as np
import nltk
import jieba #for tokenizing Chinese
import matplotlib.pyplot as plt
import plotly.express as px
import plotly.graph_objects as go
import collections
import random
import operator
import io

from wordcloud import WordCloud
import matplotlib.pyplot as plt
from PIL import Image
from matplotlib import colors


#
# def get_the_information(link, referer,cookie,user_agent):
#     rate = []
#
#     for n in range(1, 2):
#         url = re.sub("currentPage=(.*?)&append", 'currentPage=' + str(n) + '&append', link)
#
#         header={
#                 'referer': referer,
#                 'cookie':  cookie,
#               'usee-agent': user_agent }
#
#         time.sleep(5)
#
#         data = requests.get(url, headers=header).text
#
#         pat = '"rateContent":"(.*?)","formMall"'
#         pat = re.compile('"rateContent":"(.*?)","fromMall"')
#         pat.findall(data)
#         rate.extend(pat.findall(data))
#
#     df = pd.DataFrame()
#     df['rate'] = rate
#     return df
#
#
# df=get_the_information('https://rate.tmall.com/list_detail_rate.htm?itemId=526571422256&spuId=523726016&sellerId=917264765&order=3&currentPage=1&append=0&content=1&tagId=&posi=&picture=&groupId=&ua=098%23E1hvr9vWvRyvUvCkvvvvvjiWP2SZgjt8RLLWgjivPmPU1jDUR2FO6jtERLcvQj1ERvhvCvvvphmvvpvZzCAycFzNznswjg1ft%2F2wjrs%2B7ek%2BvpvEvvhhvRGvvvssi9hvCvvvpZpgvpvhvvCvpvgCvvpvvPMMvvhvC9mvphvvv89Cvv9vvhhzbLg6tI9CvvOCvhECgnkgvpvIvvCvxQvvvvhvvhnavvvCa9vvBJZvvUHmvvCH19vv9fOvvhZWvvmC5p9CvhQvbUmvjc7JRqJ6EvLv%2Bb8rV8tYVVzUd34AdcvrYE7re4g7EcqvaXTAdBQaWXxreTTJhB3Y5OZghB4AVAtlYb8reTtKjwV1r2IZh7Eb39hvCvmvphv%3D&needFold=0&_ksTS=1607585465411_739&callback=jsonp740',
#                        'https://detail.tmall.com/item.htm?spm=a230r.1.14.25.6bb7396aVDXwax&id=526571422256&ns=1&abbucket=14',
#                        't=81c3a1e1ef27b3eab361582d3f0b3c49; _tb_token_=eeed5a31e153e; cookie2=196083c6f39bb46db593b2c7e14b38d9; cna=jfo+GN118QgCAVRKcxwtPGu0; xlly_s=1; hng=GLOBAL%7Czh-CN%7CUSD%7C999; dnk=maglu%5Cu9E6D; uc1=cookie16=WqG3DMC9UpAPBHGz5QBErFxlCA%3D%3D&cookie15=VT5L2FSpMGV7TQ%3D%3D&cookie14=Uoe0al0vAht1dw%3D%3D&pas=0&existShop=false&cookie21=UIHiLt3xThH8t7YQoFNq; uc3=lg2=VFC%2FuZ9ayeYq2g%3D%3D&nk2=DlGh0bUWXg%3D%3D&vt3=F8dCuAJ1IMlgH726S9Y%3D&id2=UUtMGNbJ1IfPCA%3D%3D; tracknick=maglu%5Cu9E6D; lid=maglu%E9%B9%AD; uc4=nk4=0%40DDSwHZPGSN%2FD9qOE1tQH9LxW&id4=0%40U2l2wpMkqj54k%2BGCP6OkhMfDFypw; _l_g_=Ug%3D%3D; unb=2370269143; lgc=maglu%5Cu9E6D; cookie1=UtU4AYJ2TG9wGHuitfHot7qE1z4MiTVptaOD32BlpOQ%3D; login=true; cookie17=UUtMGNbJ1IfPCA%3D%3D; _nk_=maglu%5Cu9E6D; sgcookie=E100OS2cQ%2BRBTUu0OmmrXLcPx%2BgixtTlS6iWhZBgNWHGqyk2PJogSgAOKzh5NaS9qyPAaniCsZYQWhbBp1nu9t1vBQ%3D%3D; sg=%E9%B9%AD3e; csg=72088690; enc=UhaZze0SewcDhNk1Rme7Ki2oO6r5iJtUJ6y3lhvXcTfi7O9O63kLsN45ueWAbv2OIhJl2voH5YsF6RM48RtZzg%3D%3D; l=eB__sRfcODlNYio8BOfZhurza77TTIRjBuPzaNbMiOCPOo1RCSwRWZJjK4LvCnHNHsBXR3uF8vc8BAYHJPPRokb4d_BkdlkmndC..; isg=BBkZOBEXolmp837S3FGNla2xKAPzpg1YtBrNHzvOzMCGQjjUg_d5KJ3URR40K6WQ; tfstk=cIJ1BvcsEEpEmsl4QhiF0FYmhq6NZfy1Yc_HfCDGeahiqst1iryPPUQkmyedwM1..',
#                        'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.193 Safari/537.36')
#
# punct = '!"#$%&\'()*+,-./:;<=>?@[\\]^_`{}~、《【】》\,\n \t。“（）'  # `|` is not present here
# transtab = str.maketrans(dict.fromkeys(punct, ''))
#
# df['rate'] = '|'.join(df['rate'].tolist()).translate(transtab).split('|')
#
# import pandas as pd
# import numpy as np

df=pd.read_csv('rate.csv')

df['dry_skin']=np.where(df['rate'].str.contains('干皮|干性皮肤'),1,0)
df['oil_skin']=np.where(df['rate'].str.contains('油皮|油性皮肤'),1,0)

rate=df['rate'].tolist()
print(rate)

input_dict = {"text": rate}

import paddlehub as hub
senta = hub.Module(name="senta_bilstm")
results = senta.sentiment_classify(data=input_dict)

review=[]
for result in results:
    review.append(result.get('positive_probs'))

df['positive']=pd.Series(review)

df.to_csv('rate.csv')










def clean_the_stop(x):

    stop_words = [line.strip() for line in io.open('/Users/ypi/Desktop/中文停用词表.txt', 'r', encoding='utf-8').readlines()]

    seg = jieba.cut(x, cut_all=False)

    text_split_no = []

    for words in seg:
          if words not in stop_words:
             text_split_no.append(words)

    return ','.join(text_split_no)

df['tokenized']=df['rate'].apply(clean_the_stop)


# def make_wordcloud(text):
#     mask = np.array(Image.open('/Users/ypi/Desktop/light'))
#     color_list = ['#FF0000', '#a41a1a']
#     colormap = colors.ListedColormap(color_list)
#     font = r"/System/Library/Fonts/STHeiti Light.ttc"
#     wordcloud = word_cloud = WordCloud(
#         font_path=font,
#         background_color=None,
#         mode="RGBA",
#         prefer_horizontal=1,
#         mask=mask,
#         height=800,
#         width=500,
#         scale=10,
#         colormap=colormap,  # 设置颜色
#         margin=2
#     ).generate(text)
#     plt.figure(figsize=[25, 15])
#     plt.imshow(wordcloud, interpolation="bilinear")
#     plt.axis("off")
#     plt.show()
#
# make_wordcloud(str(df['tokenized']) )
